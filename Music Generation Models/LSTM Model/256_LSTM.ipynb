{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 256 LSTM"
      ],
      "metadata": {
        "id": "v_6ugo2-lX5o"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yo2zRmK0lT7w"
      },
      "outputs": [],
      "source": [
        "# Step 1: Install Necessary Packages\n",
        "# Install pretty_midi\n",
        "!pip install pretty_midi\n",
        "# Upgrade TensorFlow to the latest version compatible with your environment\n",
        "!pip install --upgrade tensorflow\n",
        "\n",
        "# Step 2: Import Essential Libraries\n",
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "import pretty_midi\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import Sequence\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, Dropout, LSTM, Bidirectional, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import time\n",
        "import pickle\n",
        "\n",
        "# Step 3: Suppress Unnecessary Warnings and Set TensorFlow Logging Level\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "tf.get_logger().setLevel('ERROR')\n",
        "\n",
        "# Step 4: Check for Available GPUs to Leverage for Training\n",
        "gpu_devices = tf.config.list_physical_devices('GPU')\n",
        "print(\"Number of GPUs detected:\", len(gpu_devices))\n",
        "if len(gpu_devices) == 0:\n",
        "    print(\"Warning: No GPU detected. Training might be slow.\")\n",
        "\n",
        "# Step 5: Enable Mixed Precision Training for Improved Performance if Supported\n",
        "try:\n",
        "    from tensorflow.keras import mixed_precision\n",
        "    mixed_precision.set_global_policy('mixed_float16')\n",
        "    print(\"Mixed precision training is enabled.\")\n",
        "except Exception as e:\n",
        "    print(\"Mixed precision training is not supported on this device or encountered an error.\")\n",
        "    print(f\"Error: {e}\")\n",
        "\n",
        "# Step 6: Set Random Seeds to Ensure Reproducibility\n",
        "np.random.seed(123)\n",
        "tf.random.set_seed(123)\n",
        "\n",
        "# Step 7: Download and Extract the MAESTRO Dataset\n",
        "dataset_directory = 'maestro_dataset_lstm'\n",
        "if not os.path.exists(dataset_directory):\n",
        "    print(\"\\nDownloading the MAESTRO dataset...\")\n",
        "    !wget -q --show-progress https://storage.googleapis.com/magentadata/datasets/maestro/v3.0.0/maestro-v3.0.0-midi.zip\n",
        "\n",
        "    print(\"Extracting the MAESTRO dataset...\")\n",
        "    !unzip -q maestro-v3.0.0-midi.zip -d maestro_dataset_lstm\n",
        "\n",
        "# Step 8: Collect All MIDI Files\n",
        "all_midi_files = glob.glob(os.path.join(dataset_directory, '**', '*.midi'), recursive=True)\n",
        "print(f\"\\nTotal MIDI files discovered: {len(all_midi_files)}\")\n",
        "\n",
        "# Optionally limit the number of MIDI files to manage training duration\n",
        "all_midi_files = all_midi_files[:1200]  # Change this number based on how many MIDI files you want the model to train\n",
        "print(f\"Utilizing {len(all_midi_files)} MIDI files for the training process.\")\n",
        "\n",
        "# Step 9: Function to Transform MIDI Files into Note Event Sequences\n",
        "\n",
        "def extract_note_events(midi_path):\n",
        "    \"\"\"Transforms a MIDI file into a chronological sequence of note events.\"\"\"\n",
        "    try:\n",
        "        midi_object = pretty_midi.PrettyMIDI(midi_path)\n",
        "        note_events = []\n",
        "        for track in midi_object.instruments:\n",
        "            if not track.is_drum:\n",
        "                for note in track.notes:\n",
        "                    note_events.append({\n",
        "                        'note': note.pitch,\n",
        "                        'onset': note.start,\n",
        "                        'offset': note.end,\n",
        "                        'intensity': note.velocity\n",
        "                    })\n",
        "        # Arrange notes by their onset times\n",
        "        note_events.sort(key=lambda event: event['onset'])\n",
        "        return midi_object, note_events\n",
        "    except Exception as error:\n",
        "        print(f\"Failed to process {midi_path}: {error}\")\n",
        "        return None, None\n",
        "\n",
        "\n",
        "# Function to Discretize Notes into Fixed Time Steps Aligned with Beats\n",
        "def discretize_notes(note_events, midi_obj, interval=0.25):\n",
        "    \"\"\"\n",
        "    Converts note events into fixed time-step sequences based on beats.\n",
        "\n",
        "    Args:\n",
        "        note_events (list): List of note event dictionaries.\n",
        "        midi_obj (PrettyMIDI): Parsed MIDI object.\n",
        "        interval (float): Time interval in beats for discretization.\n",
        "\n",
        "    Returns:\n",
        "        discretized_sequence (list): List of active pitches per time step.\n",
        "    \"\"\"\n",
        "    beats = midi_obj.get_beats()\n",
        "    if len(beats) < 2:\n",
        "        # Use fixed intervals if beat detection is unreliable\n",
        "        beats = np.arange(0, midi_obj.get_end_time(), interval)\n",
        "    discretized_sequence = []\n",
        "    for i in range(len(beats) - 1):\n",
        "        start = beats[i]\n",
        "        end = beats[i + 1]\n",
        "        active_pitches = [event['note'] for event in note_events if event['onset'] < end and event['offset'] > start]\n",
        "        discretized_sequence.append(active_pitches)\n",
        "    return discretized_sequence\n",
        "\n",
        "# Step 10: Process All MIDI Files to Extract Sequences\n",
        "all_note_sequences = []\n",
        "sequence_durations = []\n",
        "\n",
        "print(\"\\nProcessing MIDI files to extract note sequences...\")\n",
        "start_processing_time = time.time()\n",
        "for midi_file in all_midi_files:\n",
        "    midi_obj, note_events = extract_note_events(midi_file)\n",
        "    if note_events:\n",
        "        sequence = discretize_notes(note_events, midi_obj, interval=0.25)\n",
        "        sequence_durations.append(len(sequence))\n",
        "        all_note_sequences.append(sequence)\n",
        "    else:\n",
        "        print(f\"Skipping {midi_file} due to processing errors.\")\n",
        "processing_time_elapsed = time.time() - start_processing_time\n",
        "print(f\"Completed processing in {processing_time_elapsed:.2f} seconds.\")\n",
        "\n",
        "print(f\"\\nTotal note sequences extracted: {len(all_note_sequences)}\")\n",
        "print(f\"Average sequence length: {np.mean(sequence_durations):.2f} steps\")\n",
        "print(f\"Sequence lengths range from {np.min(sequence_durations)} to {np.max(sequence_durations)} steps\")\n",
        "\n",
        "# Step 11: Create Pitch Mappings\n",
        "collected_pitches = [pitch for seq in all_note_sequences for timestep in seq for pitch in timestep]\n",
        "unique_pitches_sorted = sorted(set(collected_pitches))  # Typically 88 for standard piano\n",
        "\n",
        "# Mapping pitches to unique integer indices\n",
        "pitch_to_index_map = {pitch: idx for idx, pitch in enumerate(unique_pitches_sorted)}\n",
        "index_to_pitch_map = {idx: pitch for idx, pitch in enumerate(unique_pitches_sorted)}\n",
        "total_pitches = len(unique_pitches_sorted)\n",
        "\n",
        "print(f\"\\nTotal unique pitches identified: {total_pitches}\")\n",
        "\n",
        "# Save pitch mappings for future reference\n",
        "with open('pitch_to_index_lstm.pkl', 'wb') as pitch_idx_file:\n",
        "    pickle.dump(pitch_to_index_map, pitch_idx_file)\n",
        "with open('index_to_pitch_lstm.pkl', 'wb') as idx_pitch_file:\n",
        "    pickle.dump(index_to_pitch_map, idx_pitch_file)\n",
        "\n",
        "# Step 12: Define Hyperparameters\n",
        "input_window = 64  # Previous time steps to consider\n",
        "num_epochs = 40\n",
        "early_stop_patience = 5\n",
        "\n",
        "# Step 13: Split Data into Training, Validation, and Testing Sets\n",
        "train_data, test_data = train_test_split(all_note_sequences, test_size=0.2, random_state=42)\n",
        "train_data, validation_data = train_test_split(train_data, test_size=0.1, random_state=42)\n",
        "\n",
        "print(f\"Number of training sequences: {len(train_data)}\")\n",
        "print(f\"Number of validation sequences: {len(validation_data)}\")\n",
        "print(f\"Number of testing sequences: {len(test_data)}\")\n",
        "\n",
        "# Step 14: Define a Data Generator Class\n",
        "class LSTM_DataGenerator(Sequence):\n",
        "    def __init__(self, dataset, seq_len, batch_sz, num_pitches, pitch_map, shuffle=True):\n",
        "        \"\"\"\n",
        "        Initializes the data generator for LSTM training.\n",
        "\n",
        "        Args:\n",
        "            dataset (list): List of sequences, each containing active pitches per time step.\n",
        "            seq_len (int): Number of previous time steps to use as input.\n",
        "            batch_sz (int): Size of each data batch.\n",
        "            num_pitches (int): Total number of unique pitches.\n",
        "            pitch_map (dict): Mapping from pitch to index.\n",
        "            shuffle (bool): Whether to shuffle data after each epoch.\n",
        "        \"\"\"\n",
        "        self.dataset = dataset\n",
        "        self.sequence_length = seq_len\n",
        "        self.batch_size = batch_sz\n",
        "        self.num_pitches = num_pitches\n",
        "        self.pitch_mapping = pitch_map\n",
        "        self.shuffle = shuffle\n",
        "        self.sample_pairs = self._prepare_samples()\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def _prepare_samples(self):\n",
        "        samples = []\n",
        "        for seq in self.dataset:\n",
        "            if len(seq) < self.sequence_length + 1:\n",
        "                continue\n",
        "            for i in range(len(seq) - self.sequence_length):\n",
        "                input_seq = seq[i:i + self.sequence_length]\n",
        "                target_seq = seq[i + 1:i + self.sequence_length + 1]\n",
        "                samples.append((input_seq, target_seq))\n",
        "        return samples\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.ceil(len(self.sample_pairs) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        batch_samples = self.sample_pairs[idx * self.batch_size : (idx + 1) * self.batch_size]\n",
        "        X = np.zeros((len(batch_samples), self.sequence_length, self.num_pitches), dtype=np.float32)\n",
        "        Y = np.zeros((len(batch_samples), self.sequence_length, self.num_pitches), dtype=np.float32)\n",
        "\n",
        "        for i, (input_seq, target_seq) in enumerate(batch_samples):\n",
        "            for t, pitches in enumerate(input_seq):\n",
        "                for pitch in pitches:\n",
        "                    if pitch in self.pitch_mapping:\n",
        "                        pitch_idx = self.pitch_mapping[pitch]\n",
        "                        if 0 <= pitch_idx < self.num_pitches:\n",
        "                            X[i, t, pitch_idx] = 1.0\n",
        "            for t, pitches in enumerate(target_seq):\n",
        "                for pitch in pitches:\n",
        "                    if pitch in self.pitch_mapping:\n",
        "                        pitch_idx = self.pitch_mapping[pitch]\n",
        "                        if 0 <= pitch_idx < self.num_pitches:\n",
        "                            Y[i, t, pitch_idx] = 1.0\n",
        "        return X, Y\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        if self.shuffle:\n",
        "            random.shuffle(self.sample_pairs)\n",
        "\n",
        "# Step 15: Initialize Data Generators\n",
        "training_generator = LSTM_DataGenerator(train_data, input_window, batch_size, total_pitches, pitch_to_index_map)\n",
        "validation_generator = LSTM_DataGenerator(validation_data, input_window, batch_size, total_pitches, pitch_to_index_map, shuffle=False)\n",
        "testing_generator = LSTM_DataGenerator(test_data, input_window, batch_size, total_pitches, pitch_to_index_map, shuffle=False)\n",
        "\n",
        "# Step 16: Define Dice Loss Function\n",
        "# The following implementation was adapted from Stack Overflow (2024)\n",
        "# Reference: Correct Implementation of Dice Loss in Tensorflow / Keras.\n",
        "# Available at: https://stackoverflow.com/questions/72195156/correct-implementation-of-dice-loss-in-tensorflow-keras\n",
        "\n",
        "def dice_loss(y_true, y_pred, smooth=1):\n",
        "    \"\"\"\n",
        "    Computes the Dice Loss for multi-label classification.\n",
        "\n",
        "    Args:\n",
        "        y_true (tensor): Ground truth binary labels.\n",
        "        y_pred (tensor): Predicted probabilities.\n",
        "        smooth (float): Smoothing factor to prevent division by zero.\n",
        "\n",
        "    Returns:\n",
        "        tensor: Dice loss value.\n",
        "    \"\"\"\n",
        "    y_true_f = tf.reshape(y_true, [-1, total_pitches])\n",
        "    y_pred_f = tf.reshape(y_pred, [-1, total_pitches])\n",
        "    intersection = tf.reduce_sum(y_true_f * y_pred_f, axis=1)\n",
        "    sum_labels = tf.reduce_sum(y_true_f, axis=1)\n",
        "    sum_preds = tf.reduce_sum(y_pred_f, axis=1)\n",
        "    dice_coeff = (2. * intersection + smooth) / (sum_labels + sum_preds + smooth)\n",
        "    return 1 - tf.reduce_mean(dice_coeff)\n",
        "\n",
        "# Step 17: Build the LSTM Model Architecture\n",
        "# The following implementation was inspired from Tensor Flow Sample (2024)\n",
        "# Reference: tf.keras.layers.Bidirectional.\n",
        "# Available at: https://www.tensorflow.org/api_docs/python/tf/keras/layers/Bidirectional\n",
        "\n",
        "print(\"\\nConstructing the LSTM-based music generation model...\")\n",
        "\n",
        "# Define the input layer with the specified sequence length and number of pitches\n",
        "input_tensor = Input(shape=(input_window, total_pitches), name='lstm_input_layer')\n",
        "\n",
        "# First Bidirectional LSTM Layer with Enhanced Units and Dropout\n",
        "first_bidirectional_lstm = Bidirectional(\n",
        "    LSTM(units=256, return_sequences=True, dropout=0.3),\n",
        "    name='bidirectional_lstm_layer_1'\n",
        ")(input_tensor)\n",
        "\n",
        "# Batch Normalization for Stabilizing Learning\n",
        "first_batch_norm = BatchNormalization(name='batch_normalization_1')(first_bidirectional_lstm)\n",
        "\n",
        "# Second Bidirectional LSTM Layer with Increased Units\n",
        "second_bidirectional_lstm = Bidirectional(\n",
        "    LSTM(units=256, return_sequences=True, dropout=0.3),\n",
        "    name='bidirectional_lstm_layer_2'\n",
        ")(first_batch_norm)\n",
        "\n",
        "# Batch Normalization\n",
        "second_batch_norm = BatchNormalization(name='batch_normalization_2')(second_bidirectional_lstm)\n",
        "\n",
        "# Third Bidirectional LSTM Layer to Capture Deeper Temporal Patterns\n",
        "third_bidirectional_lstm = Bidirectional(\n",
        "    LSTM(units=256, return_sequences=True, dropout=0.3),\n",
        "    name='bidirectional_lstm_layer_3'\n",
        ")(second_batch_norm)\n",
        "\n",
        "# Batch Normalization\n",
        "third_batch_norm = BatchNormalization(name='batch_normalization_3')(third_bidirectional_lstm)\n",
        "\n",
        "# Dense Output Layer with Sigmoid Activation for Multi-Label Prediction\n",
        "output_layer = Dense(total_pitches, activation='sigmoid', name='lstm_output_layer')(third_batch_norm)\n",
        "\n",
        "# Assemble the Complete Model\n",
        "lstm_model = Model(inputs=input_tensor, outputs=output_layer)\n",
        "print(\"Model architecture successfully constructed.\\n\")\n",
        "\n",
        "# Step 18: Compile the Model with Dice Loss and Built-in Metrics\n",
        "\n",
        "# Compile the model with Dice Loss and built-in metrics\n",
        "lstm_model.compile(\n",
        "    loss=dice_loss,\n",
        "    optimizer=Adam(learning_rate=0.001),\n",
        "    metrics=[\n",
        "        'binary_accuracy',\n",
        "        tf.keras.metrics.Precision(name='precision'),\n",
        "        tf.keras.metrics.Recall(name='recall'),\n",
        "        tf.keras.metrics.AUC(name='auc')\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Display the model architecture\n",
        "lstm_model.summary()\n",
        "\n",
        "# Step 19: Set Up Callbacks for Training\n",
        "checkpoint_directory = './lstm_model_checkpoints'\n",
        "os.makedirs(checkpoint_directory, exist_ok=True)\n",
        "\n",
        "# ModelCheckpoint to save the best model based on validation loss\n",
        "checkpoint_callback = ModelCheckpoint(\n",
        "    filepath=os.path.join(checkpoint_directory, 'best_lstm_model.keras'),\n",
        "    save_weights_only=False,\n",
        "    monitor='val_loss',\n",
        "    mode='min',\n",
        "    save_best_only=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# EarlyStopping to prevent overfitting by halting training when validation loss stops improving\n",
        "early_stopping_callback = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=early_stop_patience,\n",
        "    verbose=1,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "# ReduceLROnPlateau to reduce learning rate when a metric has stopped improving\n",
        "reduce_lr_callback = ReduceLROnPlateau(\n",
        "    monitor='val_loss',\n",
        "    factor=0.5,\n",
        "    patience=2,\n",
        "    verbose=1,\n",
        "    min_lr=1e-6\n",
        ")\n",
        "\n",
        "# Aggregate all callbacks into a list\n",
        "training_callbacks = [checkpoint_callback, early_stopping_callback, reduce_lr_callback]\n",
        "\n",
        "# Step 20: Serialize and Save Training Sequences for Generation\n",
        "def save_training_seeds(training_sequences, window_length):\n",
        "    \"\"\"\n",
        "    Saves processed training sequences to a pickle file for seed selection during generation.\n",
        "\n",
        "    Args:\n",
        "        training_sequences (list): List of training sequences with integer-encoded pitches.\n",
        "        window_length (int): The length of the input sequence window.\n",
        "\n",
        "    Saves:\n",
        "        'lstm_train_seeds.pkl': Pickle file containing processed training sequences.\n",
        "    \"\"\"\n",
        "    serialized_seeds = []\n",
        "    for sequence in training_sequences:\n",
        "        encoded_sequence = []\n",
        "        for timestep in sequence:\n",
        "            encoded_timestep = [pitch_idx for pitch_idx in timestep if pitch_idx in pitch_to_index_map]\n",
        "            if encoded_timestep:\n",
        "                encoded_sequence.append(encoded_timestep)\n",
        "        if len(encoded_sequence) >= window_length:\n",
        "            serialized_seeds.append(encoded_sequence)\n",
        "    with open('lstm_train_seeds.pkl', 'wb') as f:\n",
        "        pickle.dump(serialized_seeds, f)\n",
        "    print(\"Training sequences have been serialized and saved to 'lstm_train_seeds.pkl'.\")\n",
        "\n",
        "# Execute the serialization of training sequences\n",
        "save_training_seeds(train_data, input_window)\n",
        "\n",
        "# Step 21: Begin Model Training\n",
        "print(\"\\nCommencing the training process for the LSTM model...\")\n",
        "training_history = lstm_model.fit(\n",
        "    training_generator,\n",
        "    validation_data=validation_generator,\n",
        "    epochs=num_epochs,\n",
        "    callbacks=training_callbacks,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Step 22: Evaluate Model Performance on the Test Set\n",
        "print(\"\\nAssessing model performance on the test dataset...\")\n",
        "test_metrics = lstm_model.evaluate(testing_generator, verbose=1)\n",
        "print(f\"Test Loss: {test_metrics[0]}\")\n",
        "print(f\"Test Binary Accuracy: {test_metrics[1]}\")\n",
        "print(f\"Test Precision: {test_metrics[2]}\")\n",
        "print(f\"Test Recall: {test_metrics[3]}\")\n",
        "print(f\"Test AUC: {test_metrics[4]}\")\n",
        "\n",
        "# Step 23: Save the Final Trained Model\n",
        "lstm_model.save('final_lstm_music_model.keras')\n",
        "print(\"The trained LSTM model has been saved as 'final_lstm_music_model.keras'.\")\n",
        "\n",
        "# Step 24: Visualize Training and Validation Metrics\n",
        "def plot_training_metrics(history):\n",
        "    \"\"\"\n",
        "    Plots the training and validation metrics over each epoch.\n",
        "\n",
        "    Args:\n",
        "        history (History): Keras History object containing training metrics.\n",
        "    \"\"\"\n",
        "    metrics_to_plot = ['loss', 'binary_accuracy', 'precision', 'recall', 'auc']\n",
        "\n",
        "    plt.figure(figsize=(25, 15))\n",
        "\n",
        "    for idx, metric in enumerate(metrics_to_plot, 1):\n",
        "        plt.subplot(3, 2, idx)\n",
        "        plt.plot(history.history[metric], label=f'Training {metric}')\n",
        "        plt.plot(history.history[f'val_{metric}'], label=f'Validation {metric}')\n",
        "        plt.title(f'{metric.replace(\"_\", \" \").title()} Over Epochs')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel(metric.replace(\"_\", \" \").title())\n",
        "        plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Generate plots for training history\n",
        "plot_training_metrics(training_history)\n"
      ]
    }
  ]
}