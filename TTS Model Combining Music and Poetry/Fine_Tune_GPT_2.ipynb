{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Fine Tune GPT-2\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "v_6ugo2-lX5o"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yo2zRmK0lT7w"
      },
      "outputs": [],
      "source": [
        "!pip install pretty_midi tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pydub"
      ],
      "metadata": {
        "id": "jsor7t8y0zCO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get update\n",
        "!apt-get install fluidsynth"
      ],
      "metadata": {
        "id": "9c64cLfH03S9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pyttsx3"
      ],
      "metadata": {
        "id": "VM8jARe205Bb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get update && apt-get install -y espeak\n"
      ],
      "metadata": {
        "id": "lxG6ujsm068z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install -y musescore3 # Install MuseScore3\n"
      ],
      "metadata": {
        "id": "Y9iRv6cE085J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install gtts\n"
      ],
      "metadata": {
        "id": "AcnRWXu10-qH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pyttsx3\n",
        "from gtts import gTTS\n",
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model\n",
        "import pickle\n",
        "import random\n",
        "from music21 import converter, instrument, note, stream\n",
        "from pydub import AudioSegment\n",
        "import subprocess\n",
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Q466Xoaf1AtV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model\n",
        "import pickle\n",
        "import random\n",
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
        "from google.colab import drive\n",
        "from music21 import converter, instrument, note, stream\n",
        "from pydub import AudioSegment\n",
        "import pretty_midi\n",
        "from gtts import gTTS\n",
        "import subprocess\n",
        "\n",
        "# Suppress unnecessary TensorFlow warnings to make logs cleaner\n",
        "tf.get_logger().setLevel('ERROR')\n",
        "\n",
        "# Mount Google Drive to access stored models and data\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Load the fine-tuned GPT-2 model and tokenizer from Google Drive to generate poetry\n",
        "model_path = '/content/drive/MyDrive/gpt2-finetuned-poetry'\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(model_path)\n",
        "model = GPT2LMHeadModel.from_pretrained(model_path)\n",
        "\n",
        "# Load the LSTM model for music generation, along with the pitch mappings, from Google Drive\n",
        "lstm_model_path = '/content/drive/MyDrive/final_lstm_music_model.keras'\n",
        "pitch_to_idx_path = '/content/drive/MyDrive/pitch_to_index_lstm.pkl'\n",
        "idx_to_pitch_path = '/content/drive/MyDrive/index_to_pitch_lstm.pkl'\n",
        "seed_path = '/content/drive/MyDrive/lstm_train_seeds.pkl'\n",
        "\n",
        "# Helper function to load the LSTM model and pitch mappings\n",
        "def load_lstm_model_and_mappings():\n",
        "    lstm_model = load_model(lstm_model_path, compile=False)\n",
        "    with open(pitch_to_idx_path, 'rb') as f:\n",
        "        pitch_to_idx = pickle.load(f)\n",
        "    with open(idx_to_pitch_path, 'rb') as f:\n",
        "        idx_to_pitch = pickle.load(f)\n",
        "    return lstm_model, pitch_to_idx, idx_to_pitch\n",
        "\n",
        "# Helper function to load pre-generated seed sequences for LSTM model input\n",
        "def load_seed_sequences(seeds_file=seed_path):\n",
        "    with open(seeds_file, 'rb') as f:\n",
        "        seed_sequences = pickle.load(f)\n",
        "    return seed_sequences\n",
        "\n",
        "# Load LSTM model and data mappings\n",
        "lstm_model, pitch_to_idx, idx_to_pitch = load_lstm_model_and_mappings()\n",
        "seed_sequences = load_seed_sequences()\n",
        "\n",
        "# Function to generate poetry using GPT-2 Fine tuned model\n",
        "def generate_poem():\n",
        "    print(\"Generating poem...\")\n",
        "    # Ask the user for poet and genre selection, plus a seed text to start generating\n",
        "    selected_poet = input(\"Enter the poet token (e.g., <Poet:Shakespeare>): \").strip()\n",
        "    selected_genre = input(\"Enter the genre token (e.g., <Genre:Romantic>): \").strip()\n",
        "    seed_text = input(\"Enter the starting seed text: \").strip()\n",
        "    input_text = f'{selected_poet} {selected_genre} {seed_text}'\n",
        "\n",
        "    # Tokenize the input and generate poetry based on it\n",
        "    inputs = tokenizer(input_text, return_tensors=\"pt\")\n",
        "    outputs = model.generate(\n",
        "        inputs['input_ids'],\n",
        "        max_length=200,\n",
        "        temperature=0.7,\n",
        "        top_p=0.9,\n",
        "        do_sample=True,\n",
        "        no_repeat_ngram_size=2,\n",
        "        pad_token_id=tokenizer.eos_token_id\n",
        "    )\n",
        "\n",
        "    # Decode the generated text and clean up unnecessary tokens\n",
        "    generated_poem = tokenizer.decode(outputs[0], skip_special_tokens=False)\n",
        "    cleaned_poem = generated_poem.replace(selected_poet, '').replace(selected_genre, '').replace('[PAD]', '').replace('<LINE_BREAK>', '\\n').strip()\n",
        "\n",
        "    return cleaned_poem\n",
        "\n",
        "# Function to generate a music sequence using the LSTM model\n",
        "def generate_music_sequence(model, seeds, idx_to_pitch, seq_length=64, generation_steps=200, temperature=1.0, activation_threshold=0.5):\n",
        "    # Pick a random seed sequence and initialize with it\n",
        "    seed_sequence = random.choice(seeds)\n",
        "    generated_sequence = seed_sequence.copy()\n",
        "\n",
        "    # Generate new notes by predicting based on the current sequence\n",
        "    for step in range(generation_steps):\n",
        "        input_array = np.zeros((1, seq_length, len(idx_to_pitch)), dtype=np.float32)\n",
        "        for t in range(seq_length):\n",
        "            if len(generated_sequence) >= seq_length:\n",
        "                current_step = generated_sequence[-seq_length + t]\n",
        "            else:\n",
        "                current_step = generated_sequence[:t+1]\n",
        "            for pitch_idx in current_step:\n",
        "                if 0 <= pitch_idx < len(idx_to_pitch):\n",
        "                    input_array[0, t, pitch_idx] = 1.0  # Multi-hot encode each note\n",
        "\n",
        "        predictions = model.predict(input_array, verbose=0)[0, -1]\n",
        "        scaled_predictions = np.log(predictions + 1e-8) / temperature\n",
        "        exp_predictions = np.exp(scaled_predictions)\n",
        "        probabilities = exp_predictions / np.sum(exp_predictions)\n",
        "\n",
        "        # Determine active pitches by thresholding probabilities\n",
        "        active_pitches = [idx for idx, prob in enumerate(probabilities) if prob > activation_threshold]\n",
        "        if not active_pitches:\n",
        "            active_pitches = [np.argmax(probabilities)]\n",
        "\n",
        "        generated_sequence.append(active_pitches)\n",
        "\n",
        "    return generated_sequence\n",
        "\n",
        "# Function to convert the generated music sequence into a MIDI file\n",
        "def convert_sequence_to_midi(generated_sequence, idx_to_pitch, output_file='lstm_generated_music.mid', step_duration=0.25, velocity=100):\n",
        "    midi_obj = pretty_midi.PrettyMIDI()\n",
        "    piano_program = pretty_midi.instrument_name_to_program('Acoustic Grand Piano')\n",
        "    piano = pretty_midi.Instrument(program=piano_program)\n",
        "\n",
        "    # Keep track of time for each note\n",
        "    current_time = 0.0\n",
        "    active_notes = {}\n",
        "\n",
        "    for pitches in generated_sequence:\n",
        "        pitches_to_remove = set(active_notes.keys()) - set(pitches)\n",
        "        for pitch in pitches_to_remove:\n",
        "            note = active_notes[pitch]\n",
        "            note.end = current_time\n",
        "            piano.notes.append(note)\n",
        "            del active_notes[pitch]\n",
        "\n",
        "        for pitch in pitches:\n",
        "            if pitch not in active_notes:\n",
        "                new_note = pretty_midi.Note(\n",
        "                    velocity=velocity,\n",
        "                    pitch=pitch,\n",
        "                    start=current_time,\n",
        "                    end=current_time + step_duration\n",
        "                )\n",
        "                active_notes[pitch] = new_note\n",
        "            else:\n",
        "                active_notes[pitch].end = current_time + step_duration\n",
        "\n",
        "        current_time += step_duration\n",
        "\n",
        "    for pitch, note in active_notes.items():\n",
        "        note.end = current_time\n",
        "        piano.notes.append(note)\n",
        "\n",
        "    midi_obj.instruments.append(piano)\n",
        "    midi_obj.write(output_file)\n",
        "\n",
        "# Function to convert MIDI to WAV format using FluidSynth\n",
        "def convert_midi_to_wav(midi_path, wav_path):\n",
        "    cmd = ['fluidsynth', '-ni', '/path/to/FluidR3_GM.sf2', midi_path, '-F', wav_path, '-r', '44100']\n",
        "    subprocess.run(cmd, check=True)\n",
        "\n",
        "# Generate music, save it as MIDI, then convert to MP3\n",
        "def generate_and_save_music(complete_poem, output_midi='background_music.mid'):\n",
        "    generated_sequence = generate_music_sequence(lstm_model, seed_sequences, idx_to_pitch)\n",
        "    convert_sequence_to_midi(generated_sequence, idx_to_pitch, output_file=output_midi)\n",
        "\n",
        "    midi_path = output_midi\n",
        "    wav_path = 'output.wav'\n",
        "    convert_midi_to_wav(midi_path, wav_path)\n",
        "    sound = AudioSegment.from_wav(wav_path)\n",
        "    sound.export('background_music.mp3', format='mp3')\n",
        "\n",
        "# Function to read the generated poem using gTTS, turning it into audio\n",
        "def read_poetry_poetically(poem, output_file='poem_audio.mp3'):\n",
        "    print(\"Reading poem in a poetic way...\")\n",
        "\n",
        "    lines = poem.split('. ')\n",
        "    audio_segments = []\n",
        "\n",
        "    for idx, line in enumerate(lines):\n",
        "        poetic_line = f'{line.strip()}.'\n",
        "\n",
        "        tts = gTTS(text=poetic_line, lang='en')\n",
        "        temp_file = f'temp_line_{idx}.mp3'\n",
        "        tts.save(temp_file)\n",
        "\n",
        "        audio_segment = AudioSegment.from_mp3(temp_file)\n",
        "        audio_segments.append(audio_segment)\n",
        "\n",
        "        # Add a pause after each line for rhythm variation\n",
        "        pause_duration = 1000 if idx % 2 == 0 else 1500\n",
        "        silence = AudioSegment.silent(duration=pause_duration)\n",
        "        audio_segments.append(silence)\n",
        "\n",
        "        os.remove(temp_file)\n",
        "\n",
        "    combined_audio = audio_segments[0]\n",
        "    for segment in audio_segments[1:]:\n",
        "        combined_audio += segment\n",
        "\n",
        "    combined_audio.export(output_file, format='mp3')\n",
        "    print(f\"Poetry audio saved as {output_file}.\")\n",
        "\n",
        "# Function to loop background music to match the poem's duration\n",
        "def loop_background_music(music, target_duration):\n",
        "    loops_needed = int(target_duration / len(music)) + 1\n",
        "    extended_music = music * loops_needed\n",
        "    return extended_music[:target_duration]\n",
        "\n",
        "# Main execution flow for poetry and music generation\n",
        "if __name__ == \"__main__\":\n",
        "    complete_poem = generate_poem()\n",
        "    print(\"Complete Poem:\")\n",
        "    print(complete_poem)\n",
        "\n",
        "    generate_and_save_music(complete_poem)\n",
        "    read_poetry_poetically(complete_poem, 'poem_audio.mp3')\n",
        "\n",
        "    poem_audio = AudioSegment.from_mp3('poem_audio.mp3')\n",
        "    music_background = AudioSegment.from_mp3('background_music.mp3')\n",
        "\n",
        "    extended_music_background = loop_background_music(music_background, len(poem_audio))\n",
        "\n",
        "    combined_audio = poem_audio.overlay(extended_music_background)\n",
        "    combined_audio.export('final_output.mp3', format='mp3')\n",
        "    print(\"Final output saved as 'final_output.mp3'.\")\n"
      ],
      "metadata": {
        "id": "cHR_y5hf1Fwt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}